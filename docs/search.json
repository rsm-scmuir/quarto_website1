[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scotland’s Website",
    "section": "",
    "text": "Welcome to my website!\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html",
    "href": "projects/project1/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse. In a large-scale natural field experiment, Dean Karlan and John List partnered with a liberal nonprofit organization (that focuses on Civil Rights) in the United States to investigate how matching gift offers affect charitable giving. The donations will be tax-deuctible for federal income taxes. The study involved 50,083 individuals who had donated to the organization at least once since 1991. These prior donors were randomly divided into a control group and a treatment group. The control group received a standard direct mail fundraising letter, while the treatment group received an otherwise identical letter that included a matching grant offer from a “concerned fellow member.” Within the treatment group, participants were further randomly assigned to different variations across three key dimensions: (1) the match ratio—$1:$1, $2:$1, or $3:$1; (2) the maximum amount available from the matching donor—$25,000, $50,000, $100,000, or unspecified; and (3) the suggested donation amount, which was either equal to, 1.25 times, or 1.5 times the recipient’s previous highest contribution. These design elements allowed the researchers to isolate and test the effects of both the presence and structure of matching incentives on giving behavior. All letters were mailed in August 2005, and the fundraising appeal was tied to a current political issue at the time—Supreme Court nominations—to enhance relevance and urgency.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html#introduction",
    "href": "projects/project1/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse. In a large-scale natural field experiment, Dean Karlan and John List partnered with a liberal nonprofit organization (that focuses on Civil Rights) in the United States to investigate how matching gift offers affect charitable giving. The donations will be tax-deuctible for federal income taxes. The study involved 50,083 individuals who had donated to the organization at least once since 1991. These prior donors were randomly divided into a control group and a treatment group. The control group received a standard direct mail fundraising letter, while the treatment group received an otherwise identical letter that included a matching grant offer from a “concerned fellow member.” Within the treatment group, participants were further randomly assigned to different variations across three key dimensions: (1) the match ratio—$1:$1, $2:$1, or $3:$1; (2) the maximum amount available from the matching donor—$25,000, $50,000, $100,000, or unspecified; and (3) the suggested donation amount, which was either equal to, 1.25 times, or 1.5 times the recipient’s previous highest contribution. These design elements allowed the researchers to isolate and test the effects of both the presence and structure of matching incentives on giving behavior. All letters were mailed in August 2005, and the fundraising appeal was tied to a current political issue at the time—Supreme Court nominations—to enhance relevance and urgency.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html#data",
    "href": "projects/project1/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset includes donation outcomes (whether and how much was donated), treatment assignments (match ratio, maximum match amount, suggested donation), and individual donor history (e.g., prior donation amount and frequency). It also incorporates ZIP code-level demographics (income, education, race, household size), political context (red/blue state, voted for bush, and county), and nonprofit activity levels by state. This structure enables analysis of treatment effects and heterogeneity across political and demographic groups.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nimport pandas as pd\ndf = pd.read_stata(\"/home/jovyan/Desktop/quarto_website1/projects/project1/HW1/karlan_list_2007.dta\")\ndf['ratio1'] = (df['ratio'] == 1).astype(int)\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nimport statsmodels.formula.api as smf\n\ndef welch_t_test(x, y):\n    x = x.dropna()\n    y = y.dropna()\n    n_x, n_y = len(x), len(y)\n    mean_x, mean_y = np.mean(x), np.mean(y)\n    var_x, var_y = np.var(x, ddof=1), np.var(y, ddof=1)\n    denominator = np.sqrt((var_x / n_x) + (var_y / n_y))\n    if denominator == 0:\n        return np.nan\n    return (mean_x - mean_y) / denominator\n\ncovariates = [\n    'mrm2', 'hpa', 'years', 'female', 'couple',\n    'pwhite', 'pblack', 'ave_hh_sz', 'median_hhincome'\n]\n\nfor var in covariates:\n    print(f\"\\n--- Manual Welch t-test for {var} ---\")\n    x = df[df['treatment'] == 1][var]\n    y = df[df['treatment'] == 0][var]\n    t_stat = welch_t_test(x, y)\n    print(f\"t = {t_stat:.4f}\")\n\n    # Linear regression comparison\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params['treatment']\n    p = model.pvalues['treatment']\n    print(f\"Regression: coef = {coef:.3f}, p = {p:.4f}\")\n\n\n--- Manual Welch t-test for mrm2 ---\nt = 0.1195\nRegression: coef = 0.014, p = 0.9049\n\n--- Manual Welch t-test for hpa ---\nt = 0.9704\nRegression: coef = 0.637, p = 0.3451\n\n--- Manual Welch t-test for years ---\nt = -1.0909\nRegression: coef = -0.058, p = 0.2700\n\n--- Manual Welch t-test for female ---\nt = -1.7535\nRegression: coef = -0.008, p = 0.0787\n\n--- Manual Welch t-test for couple ---\nt = -0.5823\nRegression: coef = -0.002, p = 0.5594\n\n--- Manual Welch t-test for pwhite ---\nt = -0.5590\nRegression: coef = -0.001, p = 0.5753\n\n--- Manual Welch t-test for pblack ---\nt = 0.0975\nRegression: coef = 0.000, p = 0.9219\n\n--- Manual Welch t-test for ave_hh_sz ---\nt = 0.8234\nRegression: coef = 0.003, p = 0.4098\n\n--- Manual Welch t-test for median_hhincome ---\nt = -0.7433\nRegression: coef = -157.925, p = 0.4583\n\n\n\n\nBalance Test Results Summary\nThe Welch t-tests and linear regressions across the selected covariates indicate that there are no statistically significant differences between the treatment and control groups. This suggests that the randomization process successfully created. These balance test results support the internal validity of the experimental design by confirming that any observed differences in outcomes can likely be attributed to the treatment rather than to pre-existing group differences."
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html#experimental-results",
    "href": "projects/project1/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\n\nimport matplotlib.pyplot as plt\n\ngroup_totals = df.groupby('treatment')['amount'].sum()\ngroup_totals.index = ['Control', 'Treatment']\nplt.figure(figsize=(6, 5))\ngroup_totals.plot(kind='bar', color=['skyblue', 'salmon'])\nplt.title('Total Donations Raised by Group')\nplt.ylabel('Total Dollars Raised')\nplt.xlabel('Group')\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\n\nfrom scipy.stats import ttest_ind\n\ncontrol_gave = df[df['treatment'] == 0]['gave'].dropna()\ntreatment_gave = df[df['treatment'] == 1]['gave'].dropna()\n\nt_stat, p_val = ttest_ind(treatment_gave, control_gave, equal_var=False)\nprint(f\"T-test: t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nT-test: t = 3.209, p = 0.0013\n\n\nThe t-test shows a statistically significant difference in donation rates between the treatment and control groups (t = 3.209, p = 0.0013), supporting the hypothesis that offering a matching donation increases the likelihood of giving. This suggests that people are more inclined to donate when they perceive their contribution to have greater impact, highlighting how behavioral cues like matching grants can effectively nudge charitable behavior.\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\nimport statsmodels.formula.api as smf\n\nmodel = smf.ols('gave ~ treatment', data=df).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        18:34:46   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nmy results do compare to table 3\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\nfrom scipy.stats import ttest_ind\n\nr1 = df[df['ratio'] == 1]['gave']\nr2 = df[df['ratio2'] == 1]['gave']\nr3 = df[df['ratio3'] == 1]['gave']\n\nprint(\"T-test: 2:1 vs 1:1\")\nprint(ttest_ind(r2, r1, equal_var=False))\n\nprint(\"\\nT-test: 3:1 vs 1:1\")\nprint(ttest_ind(r3, r1, equal_var=False))\n\nprint(\"\\nT-test: 3:1 vs 2:1\")\nprint(ttest_ind(r3, r2, equal_var=False))\n\nT-test: 2:1 vs 1:1\nTtestResult(statistic=0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836)\n\nT-test: 3:1 vs 1:1\nTtestResult(statistic=1.0150174470156275, pvalue=0.31010856527625774, df=22215.0529778684)\n\nT-test: 3:1 vs 2:1\nTtestResult(statistic=0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778)\n\n\nYes these results support what the authors said on page 8\n\nInterpretation\nmy results show no statistically significant difference in donation rates between any of the match ratios tested. In other words, increasing the match ratio from 1:1 to 2:1 or 3:1 did not make people more likely to donate.\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\n\nimport statsmodels.formula.api as smf\nmodel = smf.ols('gave ~ ratio1 + ratio2 + ratio3', data=df).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        18:34:46   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe regression shows that 2:1 and 3:1 match ratios significantly increase donation rates compared to the base group. However, their effects are nearly identical, suggesting no added benefit from raising the match beyond 2:1. This supports the paper’s conclusion that while matching boosts giving, higher ratios don’t lead to more donations.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\ncoef_r2 = model.params.get('ratio2', 0)\ncoef_r3 = model.params.get('ratio3', 0)\nprint(f\"\\nDifference 2:1 vs 1:1: {coef_r2:.4f}\")\nprint(f\"Difference 3:1 vs 1:1: {coef_r3:.4f}\")\nprint(f\"Difference 3:1 vs 2:1: {coef_r3 - coef_r2:.4f}\")\n\n\nDifference 2:1 vs 1:1: 0.0048\nDifference 3:1 vs 1:1: 0.0049\nDifference 3:1 vs 2:1: 0.0001\n\n\nThe regression shows that both 2:1 and 3:1 match ratios increase donation rates by about 0.5 percentage points compared to 1:1. But there’s almost no difference between 2:1 and 3:1, so bigger match ratios don’t seem to help more. It looks like just having a match matters more than how big it is.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\ncontrol_amt = df[df['treatment'] == 0]['amount']\ntreatment_amt = df[df['treatment'] == 1]['amount']\nt_stat, p_val = ttest_ind(treatment_amt, control_amt, equal_var=False)\nprint(f\"T-test (all data): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nT-test (all data): t = 1.918, p = 0.0551\n\n\nThe t-test shows a small difference in donation amounts between the treatment and control groups, with the treatment group giving slightly more on average. However, the result is not statistically significant (p = 0.0551), meaning we cannot confidently conclude that the treatment had an effect on how much people donated.\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\n\ndf_donors = df[df['amount'] &gt; 0]\n\nc_amt = df_donors[df_donors['treatment'] == 0]['amount']\nt_amt = df_donors[df_donors['treatment'] == 1]['amount']\nt_stat, p_val = ttest_ind(t_amt, c_amt, equal_var=False)\nprint(f\"T-test (donors only): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nmodel_donors = smf.ols('amount ~ treatment', data=df_donors).fit()\nprint(model_donors.summary())\n\nT-test (donors only): t = -0.585, p = 0.5590\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        18:34:46   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe regression shows that among those who donated, individuals in the treatment group gave about $1.67 less than those in the control group, but this difference is not statistically significant (p = 0.561). This suggests that while matching offers increase the likelihood of donating, they do not affect the donation amount once a person chooses to give. Therefore, we cannot draw a causal conclusion about the treatment’s impact on contribution size.\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\nimport matplotlib.pyplot as plt\n\n\ncontrol = df_donors[df_donors['treatment'] == 0]['amount']\ntreatment = df_donors[df_donors['treatment'] == 1]['amount']\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\naxes[0].hist(control, bins=30, color='skyblue', edgecolor='black')\naxes[0].axvline(control.mean(), color='red', linestyle='dashed', label=f'Mean: ${control.mean():.2f}')\naxes[0].set_title('Control Group - Donation Amounts')\naxes[0].set_xlabel('Donation Amount ($)')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\naxes[1].hist(treatment, bins=30, color='salmon', edgecolor='black')\naxes[1].axvline(treatment.mean(), color='red', linestyle='dashed', label=f'Mean: ${treatment.mean():.2f}')\naxes[1].set_title('Treatment Group - Donation Amounts')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nn = 10000\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\n\ncontrol_draws = np.random.binomial(n=1, p=p_control, size=n)\ntreatment_draws = np.random.binomial(n=1, p=p_treatment, size=n)\n\ndifferences = treatment_draws - control_draws\n\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n + 1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff, label='Cumulative Avg. Difference')\nplt.axhline(true_diff, color='red', linestyle='dashed', label='True Difference = 0.004')\nplt.title(\"Law of Large Numbers: Cumulative Avg. Difference in Donation Rates\")\nplt.xlabel(\"Number of Simulated Pairs\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis simulation shows how the average difference in donation rates between treatment and control groups stabilizes as the sample size increases. Although early values fluctuate due to randomness, the cumulative average converges to the true difference (0.004) as more data is added. This demonstrates the Law of Large Numbers: with enough observations, sample averages reliably approach their expected values.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ncontrol_p = 0.018\ntreat_p = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, control_p, n)\n        treat = np.random.binomial(1, treat_p, n)\n        diffs.append(np.mean(treat) - np.mean(control))\n    \n \n    axes[i].hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='dashed', label='Zero')\n    axes[i].set_title(f'Sample Size = {n}')\n    axes[i].set_xlabel('Avg. Difference in Means')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAs sample size increases, the distribution of average differences becomes more concentrated and symmetric, illustrating the Central Limit Theorem. With small samples (e.g., 50), the spread is wide and variable. But by n = 1000, the distribution is nearly normal and centered around the true mean difference. Importantly, zero is in the tail, not the center, suggesting that the effect of the treatment is consistently positive across simulations."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file.\nAbout this site"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/project1/HW1/HW.html",
    "href": "projects/project1/HW1/HW.html",
    "title": "Scotland's Website",
    "section": "",
    "text": "import pandas as pd\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n\ndf = pd.read_stata(\"/home/jovyan/Desktop/quarto_website1/HW1/karlan_list_2007.dta\")\ndf['ratio1'] = (df['ratio'] == 1).astype(int)\n\n\nlist(df.columns)\n\n['treatment',\n 'control',\n 'ratio',\n 'ratio2',\n 'ratio3',\n 'size',\n 'size25',\n 'size50',\n 'size100',\n 'sizeno',\n 'ask',\n 'askd1',\n 'askd2',\n 'askd3',\n 'ask1',\n 'ask2',\n 'ask3',\n 'amount',\n 'gave',\n 'amountchange',\n 'hpa',\n 'ltmedmra',\n 'freq',\n 'years',\n 'year5',\n 'mrm2',\n 'dormant',\n 'female',\n 'couple',\n 'state50one',\n 'nonlit',\n 'cases',\n 'statecnt',\n 'stateresponse',\n 'stateresponset',\n 'stateresponsec',\n 'stateresponsetminc',\n 'perbush',\n 'close25',\n 'red0',\n 'blue0',\n 'redcty',\n 'bluecty',\n 'pwhite',\n 'pblack',\n 'page18_39',\n 'ave_hh_sz',\n 'median_hhincome',\n 'powner',\n 'psch_atlstba',\n 'pop_propurban',\n 'ratio1']\n\n\n\ndf\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\nratio1\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n1\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n1\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n1\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n0\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n0\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n0\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n0\n\n\n\n\n50083 rows × 52 columns\n\n\n\n\nimport numpy as np\n\ndef welch_t_test(x, y):\n    # Drop missing values\n    x = x.dropna()\n    y = y.dropna()\n\n    # Sample sizes\n    n_x = len(x)\n    n_y = len(y)\n\n    # Sample means\n    mean_x = np.mean(x)\n    mean_y = np.mean(y)\n\n    # Sample variances\n    var_x = np.var(x, ddof=1)\n    var_y = np.var(y, ddof=1)\n\n    # Welch's t-statistic\n    numerator = mean_x - mean_y\n    denominator = np.sqrt((var_x / n_x) + (var_y / n_y))\n\n    if denominator == 0:\n        return np.nan\n\n    t_stat = numerator / denominator\n    return t_stat\n\n\n\ncovariates = [\n    'mrm2', 'hpa', 'years', 'female', 'couple',\n    'pwhite', 'pblack', 'ave_hh_sz', 'median_hhincome'\n]\n\nfor var in covariates:\n    print(f\"\\n--- Manual Welch t-test for {var} ---\")\n    x = df[df['treatment'] == 1][var]\n    y = df[df['treatment'] == 0][var]\n    t_stat = welch_t_test(x, y)\n    print(f\"t = {t_stat:.4f}\")\n    # Linear regression\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params['treatment']\n    p = model.pvalues['treatment']\n    print(f\"Regression: coef = {coef:.3f}, p = {p:.4f}\")\n\n\n--- Manual Welch t-test for mrm2 ---\nt = 0.1195\nRegression: coef = 0.014, p = 0.9049\n\n--- Manual Welch t-test for hpa ---\nt = 0.9704\nRegression: coef = 0.637, p = 0.3451\n\n--- Manual Welch t-test for years ---\nt = -1.0909\nRegression: coef = -0.058, p = 0.2700\n\n--- Manual Welch t-test for female ---\nt = -1.7535\nRegression: coef = -0.008, p = 0.0787\n\n--- Manual Welch t-test for couple ---\nt = -0.5823\nRegression: coef = -0.002, p = 0.5594\n\n--- Manual Welch t-test for pwhite ---\nt = -0.5590\nRegression: coef = -0.001, p = 0.5753\n\n--- Manual Welch t-test for pblack ---\nt = 0.0975\nRegression: coef = 0.000, p = 0.9219\n\n--- Manual Welch t-test for ave_hh_sz ---\nt = 0.8234\nRegression: coef = 0.003, p = 0.4098\n\n--- Manual Welch t-test for median_hhincome ---\nt = -0.7433\nRegression: coef = -157.925, p = 0.4583\n\n\n\nimport matplotlib.pyplot as plt\n\n\n\ngroup_totals = df.groupby('treatment')['amount'].sum()\n\ngroup_totals.index = ['Control', 'Treatment']\n\nplt.figure(figsize=(6, 5))\ngroup_totals.plot(kind='bar', color=['skyblue', 'salmon'])\n\nplt.title('Total Donations Raised by Group')\nplt.ylabel('Total Dollars Raised')\nplt.xlabel('Group')\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\n\n\ncontrol_gave = df[df['treatment'] == 0]['gave'].dropna()\ntreatment_gave = df[df['treatment'] == 1]['gave'].dropna()\n\nt_stat, p_val = ttest_ind(treatment_gave, control_gave, equal_var=False)\nprint(f\"T-test: t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nT-test: t = 3.209, p = 0.0013\n\n\n\nimport statsmodels.formula.api as smf\n\nmodel = smf.ols('gave ~ treatment', data=df).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        17:04:45   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nimport statsmodels.api as sm\n\ndf['intercept'] = 1  # probit model requires intercept manually\nprobit_model = sm.Probit(df['gave'], df[['intercept', 'treatment']]).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        17:04:45   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Filter groups\nr1 = df[df['ratio'] == 1]['gave']\nr2 = df[df['ratio2'] == 1]['gave']\nr3 = df[df['ratio3'] == 1]['gave']\n\n# T-tests\nprint(\"T-test: 2:1 vs 1:1\")\nprint(ttest_ind(r2, r1, equal_var=False))\n\nprint(\"\\nT-test: 3:1 vs 1:1\")\nprint(ttest_ind(r3, r1, equal_var=False))\n\nprint(\"\\nT-test: 3:1 vs 2:1\")\nprint(ttest_ind(r3, r2, equal_var=False))\n\nT-test: 2:1 vs 1:1\nTtestResult(statistic=0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836)\n\nT-test: 3:1 vs 1:1\nTtestResult(statistic=1.0150174470156275, pvalue=0.31010856527625774, df=22215.0529778684)\n\nT-test: 3:1 vs 2:1\nTtestResult(statistic=0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778)\n\n\n\nimport statsmodels.formula.api as smf\n\nmodel = smf.ols('gave ~ ratio1 + ratio2 + ratio3', data=df).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        17:04:45   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\ncoef_r2 = model.params.get('ratio2', 0)\ncoef_r3 = model.params.get('ratio3', 0)\nprint(f\"\\nDifference 2:1 vs 1:1: {coef_r2:.4f}\")\nprint(f\"Difference 3:1 vs 1:1: {coef_r3:.4f}\")\nprint(f\"Difference 3:1 vs 2:1: {coef_r3 - coef_r2:.4f}\")\n\n\nDifference 2:1 vs 1:1: 0.0048\nDifference 3:1 vs 1:1: 0.0049\nDifference 3:1 vs 2:1: 0.0001\n\n\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n\n\ncontrol_amt = df[df['treatment'] == 0]['amount']\ntreatment_amt = df[df['treatment'] == 1]['amount']\nt_stat, p_val = ttest_ind(treatment_amt, control_amt, equal_var=False)\nprint(f\"T-test (all data): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n# Bivariate regression\nmodel = smf.ols('amount ~ treatment', data=df).fit()\nprint(model.summary())\n\nT-test (all data): t = 1.918, p = 0.0551\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        17:04:45   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\ndf_donors = df[df['amount'] &gt; 0]\n\nc_amt = df_donors[df_donors['treatment'] == 0]['amount']\nt_amt = df_donors[df_donors['treatment'] == 1]['amount']\nt_stat, p_val = ttest_ind(t_amt, c_amt, equal_var=False)\nprint(f\"T-test (donors only): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nmodel_donors = smf.ols('amount ~ treatment', data=df_donors).fit()\nprint(model_donors.summary())\n\nT-test (donors only): t = -0.585, p = 0.5590\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        17:04:45   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nimport matplotlib.pyplot as plt\n\n\ncontrol = df_donors[df_donors['treatment'] == 0]['amount']\ntreatment = df_donors[df_donors['treatment'] == 1]['amount']\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\naxes[0].hist(control, bins=30, color='skyblue', edgecolor='black')\naxes[0].axvline(control.mean(), color='red', linestyle='dashed', label=f'Mean: ${control.mean():.2f}')\naxes[0].set_title('Control Group - Donation Amounts')\naxes[0].set_xlabel('Donation Amount ($)')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\naxes[1].hist(treatment, bins=30, color='salmon', edgecolor='black')\naxes[1].axvline(treatment.mean(), color='red', linestyle='dashed', label=f'Mean: ${treatment.mean():.2f}')\naxes[1].set_title('Treatment Group - Donation Amounts')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nn = 10000\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\n\ncontrol_draws = np.random.binomial(n=1, p=p_control, size=n)\ntreatment_draws = np.random.binomial(n=1, p=p_treatment, size=n)\n\ndifferences = treatment_draws - control_draws\n\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n + 1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff, label='Cumulative Avg. Difference')\nplt.axhline(true_diff, color='red', linestyle='dashed', label='True Difference = 0.004')\nplt.title(\"Law of Large Numbers: Cumulative Avg. Difference in Donation Rates\")\nplt.xlabel(\"Number of Simulated Pairs\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis simulation shows how the average difference in donation rates between treatment and control groups stabilizes as the sample size increases. Although early values fluctuate due to randomness, the cumulative average converges to the true difference (0.004) as more data is added. This demonstrates the Law of Large Numbers: with enough observations, sample averages reliably approach their expected values.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\ncontrol_p = 0.018\ntreat_p = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Set up plots\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, control_p, n)\n        treat = np.random.binomial(1, treat_p, n)\n        diffs.append(np.mean(treat) - np.mean(control))\n    \n    # Plot histogram\n    axes[i].hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='dashed', label='Zero')\n    axes[i].set_title(f'Sample Size = {n}')\n    axes[i].set_xlabel('Avg. Difference in Means')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAs sample size increases, the distribution of average differences becomes more concentrated and symmetric, illustrating the Central Limit Theorem. With small samples (e.g., 50), the spread is wide and variable. But by n = 1000, the distribution is nearly normal and centered around the true mean difference. Importantly, zero is in the tail, not the center, suggesting that the effect of the treatment is consistently positive across simulations."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "My Projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\nScotland Muir\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  }
]