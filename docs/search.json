[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scotland’s Website",
    "section": "",
    "text": "Welcome to my website!\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html",
    "href": "projects/project1/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse. In a large-scale natural field experiment, Dean Karlan and John List partnered with a liberal nonprofit organization (that focuses on Civil Rights) in the United States to investigate how matching gift offers affect charitable giving. The donations will be tax-deuctible for federal income taxes. The study involved 50,083 individuals who had donated to the organization at least once since 1991. These prior donors were randomly divided into a control group and a treatment group. The control group received a standard direct mail fundraising letter, while the treatment group received an otherwise identical letter that included a matching grant offer from a “concerned fellow member.” Within the treatment group, participants were further randomly assigned to different variations across three key dimensions: (1) the match ratio—$1:$1, $2:$1, or $3:$1; (2) the maximum amount available from the matching donor—$25,000, $50,000, $100,000, or unspecified; and (3) the suggested donation amount, which was either equal to, 1.25 times, or 1.5 times the recipient’s previous highest contribution. These design elements allowed the researchers to isolate and test the effects of both the presence and structure of matching incentives on giving behavior. All letters were mailed in August 2005, and the fundraising appeal was tied to a current political issue at the time—Supreme Court nominations—to enhance relevance and urgency.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html#introduction",
    "href": "projects/project1/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse. In a large-scale natural field experiment, Dean Karlan and John List partnered with a liberal nonprofit organization (that focuses on Civil Rights) in the United States to investigate how matching gift offers affect charitable giving. The donations will be tax-deuctible for federal income taxes. The study involved 50,083 individuals who had donated to the organization at least once since 1991. These prior donors were randomly divided into a control group and a treatment group. The control group received a standard direct mail fundraising letter, while the treatment group received an otherwise identical letter that included a matching grant offer from a “concerned fellow member.” Within the treatment group, participants were further randomly assigned to different variations across three key dimensions: (1) the match ratio—$1:$1, $2:$1, or $3:$1; (2) the maximum amount available from the matching donor—$25,000, $50,000, $100,000, or unspecified; and (3) the suggested donation amount, which was either equal to, 1.25 times, or 1.5 times the recipient’s previous highest contribution. These design elements allowed the researchers to isolate and test the effects of both the presence and structure of matching incentives on giving behavior. All letters were mailed in August 2005, and the fundraising appeal was tied to a current political issue at the time—Supreme Court nominations—to enhance relevance and urgency.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html#data",
    "href": "projects/project1/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset includes donation outcomes (whether and how much was donated), treatment assignments (match ratio, maximum match amount, suggested donation), and individual donor history (e.g., prior donation amount and frequency). It also incorporates ZIP code-level demographics (income, education, race, household size), political context (red/blue state, voted for bush, and county), and nonprofit activity levels by state. This structure enables analysis of treatment effects and heterogeneity across political and demographic groups.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nimport pandas as pd\ndf = pd.read_stata(\"/home/jovyan/Desktop/quarto_website1/projects/project1/HW1/karlan_list_2007.dta\")\ndf['ratio1'] = (df['ratio'] == 1).astype(int)\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nimport statsmodels.formula.api as smf\n\ndef welch_t_test(x, y):\n    x = x.dropna()\n    y = y.dropna()\n    n_x, n_y = len(x), len(y)\n    mean_x, mean_y = np.mean(x), np.mean(y)\n    var_x, var_y = np.var(x, ddof=1), np.var(y, ddof=1)\n    denominator = np.sqrt((var_x / n_x) + (var_y / n_y))\n    if denominator == 0:\n        return np.nan\n    return (mean_x - mean_y) / denominator\n\ncovariates = [\n    'mrm2', 'hpa', 'years', 'female', 'couple',\n    'pwhite', 'pblack', 'ave_hh_sz', 'median_hhincome'\n]\n\nfor var in covariates:\n    print(f\"\\n--- Manual Welch t-test for {var} ---\")\n    x = df[df['treatment'] == 1][var]\n    y = df[df['treatment'] == 0][var]\n    t_stat = welch_t_test(x, y)\n    print(f\"t = {t_stat:.4f}\")\n\n    # Linear regression comparison\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params['treatment']\n    p = model.pvalues['treatment']\n    print(f\"Regression: coef = {coef:.3f}, p = {p:.4f}\")\n\n\n--- Manual Welch t-test for mrm2 ---\nt = 0.1195\nRegression: coef = 0.014, p = 0.9049\n\n--- Manual Welch t-test for hpa ---\nt = 0.9704\nRegression: coef = 0.637, p = 0.3451\n\n--- Manual Welch t-test for years ---\nt = -1.0909\nRegression: coef = -0.058, p = 0.2700\n\n--- Manual Welch t-test for female ---\nt = -1.7535\nRegression: coef = -0.008, p = 0.0787\n\n--- Manual Welch t-test for couple ---\nt = -0.5823\nRegression: coef = -0.002, p = 0.5594\n\n--- Manual Welch t-test for pwhite ---\nt = -0.5590\nRegression: coef = -0.001, p = 0.5753\n\n--- Manual Welch t-test for pblack ---\nt = 0.0975\nRegression: coef = 0.000, p = 0.9219\n\n--- Manual Welch t-test for ave_hh_sz ---\nt = 0.8234\nRegression: coef = 0.003, p = 0.4098\n\n--- Manual Welch t-test for median_hhincome ---\nt = -0.7433\nRegression: coef = -157.925, p = 0.4583\n\n\n\n\nBalance Test Results Summary\nThe Welch t-tests and linear regressions across the selected covariates indicate that there are no statistically significant differences between the treatment and control groups. This suggests that the randomization process successfully created. These balance test results support the internal validity of the experimental design by confirming that any observed differences in outcomes can likely be attributed to the treatment rather than to pre-existing group differences."
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html#experimental-results",
    "href": "projects/project1/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\ngroup_totals = df.groupby('treatment')['amount'].sum()\ngroup_totals.index = ['Control', 'Treatment']\nplt.figure(figsize=(6, 5))\ngroup_totals.plot(kind='bar', color=['skyblue', 'salmon'])\nplt.title('Total Donations Raised by Group')\nplt.ylabel('Total Dollars Raised')\nplt.xlabel('Group')\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\ncontrol_gave = df[df['treatment'] == 0]['gave'].dropna()\ntreatment_gave = df[df['treatment'] == 1]['gave'].dropna()\n\nt_stat, p_val = ttest_ind(treatment_gave, control_gave, equal_var=False)\nprint(f\"T-test: t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nT-test: t = 3.209, p = 0.0013\n\n\nThe t-test shows a statistically significant difference in donation rates between the treatment and control groups (t = 3.209, p = 0.0013), supporting the hypothesis that offering a matching donation increases the likelihood of giving. This suggests that people are more inclined to donate when they perceive their contribution to have greater impact, highlighting how behavioral cues like matching grants can effectively nudge charitable behavior.\n\nimport statsmodels.formula.api as smf\n\nmodel = smf.ols('gave ~ treatment', data=df).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 07 May 2025   Prob (F-statistic):            0.00193\nTime:                        23:52:59   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nmy results do compare to table 3\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nfrom scipy.stats import ttest_ind\n\nr1 = df[df['ratio'] == 1]['gave']\nr2 = df[df['ratio2'] == 1]['gave']\nr3 = df[df['ratio3'] == 1]['gave']\n\nprint(\"T-test: 2:1 vs 1:1\")\nprint(ttest_ind(r2, r1, equal_var=False))\n\nprint(\"\\nT-test: 3:1 vs 1:1\")\nprint(ttest_ind(r3, r1, equal_var=False))\n\nprint(\"\\nT-test: 3:1 vs 2:1\")\nprint(ttest_ind(r3, r2, equal_var=False))\n\nT-test: 2:1 vs 1:1\nTtestResult(statistic=0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836)\n\nT-test: 3:1 vs 1:1\nTtestResult(statistic=1.0150174470156275, pvalue=0.31010856527625774, df=22215.0529778684)\n\nT-test: 3:1 vs 2:1\nTtestResult(statistic=0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778)\n\n\nYes these results support what the authors said on page 8\n\nInterpretation\nmy results show no statistically significant difference in donation rates between any of the match ratios tested. In other words, increasing the match ratio from 1:1 to 2:1 or 3:1 did not make people more likely to donate.\n\nimport statsmodels.formula.api as smf\nmodel = smf.ols('gave ~ ratio1 + ratio2 + ratio3', data=df).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Wed, 07 May 2025   Prob (F-statistic):             0.0118\nTime:                        23:52:59   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe regression shows that 2:1 and 3:1 match ratios significantly increase donation rates compared to the base group. However, their effects are nearly identical, suggesting no added benefit from raising the match beyond 2:1. This supports the paper’s conclusion that while matching boosts giving, higher ratios don’t lead to more donations.\n\ncoef_r2 = model.params.get('ratio2', 0)\ncoef_r3 = model.params.get('ratio3', 0)\nprint(f\"\\nDifference 2:1 vs 1:1: {coef_r2:.4f}\")\nprint(f\"Difference 3:1 vs 1:1: {coef_r3:.4f}\")\nprint(f\"Difference 3:1 vs 2:1: {coef_r3 - coef_r2:.4f}\")\n\n\nDifference 2:1 vs 1:1: 0.0048\nDifference 3:1 vs 1:1: 0.0049\nDifference 3:1 vs 2:1: 0.0001\n\n\nThe regression shows that both 2:1 and 3:1 match ratios increase donation rates by about 0.5 percentage points compared to 1:1. But there’s almost no difference between 2:1 and 3:1, so bigger match ratios don’t seem to help more. It looks like just having a match matters more than how big it is.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\ncontrol_amt = df[df['treatment'] == 0]['amount']\ntreatment_amt = df[df['treatment'] == 1]['amount']\nt_stat, p_val = ttest_ind(treatment_amt, control_amt, equal_var=False)\nprint(f\"T-test (all data): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nT-test (all data): t = 1.918, p = 0.0551\n\n\nThe t-test shows a small difference in donation amounts between the treatment and control groups, with the treatment group giving slightly more on average. However, the result is not statistically significant (p = 0.0551), meaning we cannot confidently conclude that the treatment had an effect on how much people donated.\n\ndf_donors = df[df['amount'] &gt; 0]\n\nc_amt = df_donors[df_donors['treatment'] == 0]['amount']\nt_amt = df_donors[df_donors['treatment'] == 1]['amount']\nt_stat, p_val = ttest_ind(t_amt, c_amt, equal_var=False)\nprint(f\"T-test (donors only): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nmodel_donors = smf.ols('amount ~ treatment', data=df_donors).fit()\nprint(model_donors.summary())\n\nT-test (donors only): t = -0.585, p = 0.5590\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 07 May 2025   Prob (F-statistic):              0.561\nTime:                        23:53:00   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThe regression shows that among those who donated, individuals in the treatment group gave about $1.67 less than those in the control group, but this difference is not statistically significant (p = 0.561). This suggests that while matching offers increase the likelihood of donating, they do not affect the donation amount once a person chooses to give. Therefore, we cannot draw a causal conclusion about the treatment’s impact on contribution size.\n\nimport matplotlib.pyplot as plt\n\n\ncontrol = df_donors[df_donors['treatment'] == 0]['amount']\ntreatment = df_donors[df_donors['treatment'] == 1]['amount']\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\naxes[0].hist(control, bins=30, color='skyblue', edgecolor='black')\naxes[0].axvline(control.mean(), color='red', linestyle='dashed', label=f'Mean: ${control.mean():.2f}')\naxes[0].set_title('Control Group - Donation Amounts')\naxes[0].set_xlabel('Donation Amount ($)')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\naxes[1].hist(treatment, bins=30, color='salmon', edgecolor='black')\naxes[1].axvline(treatment.mean(), color='red', linestyle='dashed', label=f'Mean: ${treatment.mean():.2f}')\naxes[1].set_title('Treatment Group - Donation Amounts')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/project1/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nn = 10000\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\n\ncontrol_draws = np.random.binomial(n=1, p=p_control, size=n)\ntreatment_draws = np.random.binomial(n=1, p=p_treatment, size=n)\n\ndifferences = treatment_draws - control_draws\n\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n + 1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff, label='Cumulative Avg. Difference')\nplt.axhline(true_diff, color='red', linestyle='dashed', label='True Difference = 0.004')\nplt.title(\"Law of Large Numbers: Cumulative Avg. Difference in Donation Rates\")\nplt.xlabel(\"Number of Simulated Pairs\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis simulation shows how the average difference in donation rates between treatment and control groups stabilizes as the sample size increases. Although early values fluctuate due to randomness, the cumulative average converges to the true difference (0.004) as more data is added. This demonstrates the Law of Large Numbers: with enough observations, sample averages reliably approach their expected values.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ncontrol_p = 0.018\ntreat_p = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, control_p, n)\n        treat = np.random.binomial(1, treat_p, n)\n        diffs.append(np.mean(treat) - np.mean(control))\n    \n \n    axes[i].hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='dashed', label='Zero')\n    axes[i].set_title(f'Sample Size = {n}')\n    axes[i].set_xlabel('Avg. Difference in Means')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAs sample size increases, the distribution of average differences becomes more concentrated and symmetric, illustrating the Central Limit Theorem. With small samples (e.g., 50), the spread is wide and variable. But by n = 1000, the distribution is nearly normal and centered around the true mean difference. Importantly, zero is in the tail, not the center, suggesting that the effect of the treatment is consistently positive across simulations."
  },
  {
    "objectID": "projects/project1/HW2/HW2.html",
    "href": "projects/project1/HW2/HW2.html",
    "title": "next section",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load the datasets\nblueprinty = pd.read_csv(\"/home/jovyan/Desktop/quarto_website1/projects/project1/HW2/blueprinty.csv\")\nairbnb = pd.read_csv(\"/home/jovyan/Desktop/quarto_website1/projects/project1/HW2/airbnb.csv\")\n\n\n\n\nprint(blueprinty.head())\n\n   patents     region   age  iscustomer\n0        0    Midwest  32.5           0\n1        3  Southwest  37.5           0\n2        4  Northwest  27.0           1\n3        3  Northeast  24.5           0\n4        3  Southwest  37.0           0\n\n\n\nprint(airbnb.head())\n\n   Unnamed: 0    id  days last_scraped  host_since        room_type  \\\n0           1  2515  3130     4/2/2017    9/6/2008     Private room   \n1           2  2595  3127     4/2/2017    9/9/2008  Entire home/apt   \n2           3  3647  3050     4/2/2017  11/25/2008     Private room   \n3           4  3831  3038     4/2/2017   12/7/2008  Entire home/apt   \n4           5  4611  3012     4/2/2017    1/2/2009     Private room   \n\n   bathrooms  bedrooms  price  number_of_reviews  review_scores_cleanliness  \\\n0        1.0       1.0     59                150                        9.0   \n1        1.0       0.0    230                 20                        9.0   \n2        1.0       1.0    150                  0                        NaN   \n3        1.0       1.0     89                116                        9.0   \n4        NaN       1.0     39                 93                        9.0   \n\n   review_scores_location  review_scores_value instant_bookable  \n0                     9.0                  9.0                f  \n1                    10.0                  9.0                f  \n2                     NaN                  NaN                f  \n3                     9.0                  9.0                f  \n4                     8.0                  9.0                t  \n\n\n\n\nmean_patents = blueprinty.groupby(\"iscustomer\")[\"patents\"].mean()\nprint(\"\\n📊 Mean Patents by Customer Status:\")\nprint(mean_patents)\n\nplt.figure(figsize=(10, 6))\nsns.histplot(data=blueprinty, x=\"patents\", hue=\"iscustomer\", kde=False, bins=20, element=\"step\", stat=\"density\")\nplt.title(\"Distribution of Number of Patents by Customer Status\")\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Density\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n📊 Mean Patents by Customer Status:\niscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\n\n\n\n\n\n\n\n\nOn average, Blueprinty customers have more patents than non-customers.\nThe histogram shows that customers are more likely to have higher patent counts, while non-customers are concentrated at the lower end.\nThis suggests that Blueprinty may be associated with higher patenting activity. However, it’s important to note that correlation does not imply causation — customers may already be more innovative or resource-rich firms.\n\n\n# 📊 Mean Age by Customer Status\nmean_age = blueprinty.groupby(\"iscustomer\")[\"age\"].mean()\nprint(\"\\n📊 Mean Age by Customer Status:\")\nprint(mean_age)\n\n# 📈 Distribution of Age\nplt.figure(figsize=(10, 6))\nsns.histplot(data=blueprinty, x=\"age\", hue=\"iscustomer\", kde=False, bins=20, element=\"step\", stat=\"density\")\nplt.title(\"Distribution of Firm Age by Customer Status\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Density\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# 📍 Count of Regions by Customer Status\nplt.figure(figsize=(10, 6))\nsns.countplot(data=blueprinty, x=\"region\", hue=\"iscustomer\")\nplt.title(\"Count of Firms by Region and Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Number of Firms\")\nplt.grid(True, axis='y')\nplt.tight_layout()\nplt.show()\n\n\n📊 Mean Age by Customer Status:\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAge: Blueprinty customers tend to be slightly older on average than non-customers. The age distribution shows a small shift toward the right for customers.\nRegion: Certain regions have more customers than others, indicating possible geographical bias. For example, if the majority of customers are from tech-focused or IP-heavy regions, this could skew the results.\nThese findings are important because they show that customer status is not randomly assigned — older firms or firms in specific regions might be more likely to adopt Blueprinty, independent of its actual effect.\n\n\nEstimation of Simple Poisson Model\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nLet ( Y_i () ), then the probability mass function is:\n[ f(Y_i|) = ]\nThe log-likelihood function for a sample of size ( n ) is:\n[ () = _{i=1}^n ( -+ Y_i () - (Y_i!) ) ]\ntodo: Code the likelihood (or log-likelihood) function\n\nimport numpy as np\nfrom scipy.special import gammaln  # stable log-factorial\n\ndef poisson_loglikelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return -np.inf\n    return np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n\ntodo: Use your function to plot lambda on the horizontal axis…\n\nY = blueprinty[\"patents\"].values\nlambdas = np.linspace(0.1, 10, 100)\nlog_liks = [poisson_loglikelihood(l, Y) for l in lambdas]\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambdas, log_liks)\nplt.xlabel(\"Lambda\")\nplt.ylabel(\"Log-Likelihood\")\nplt.title(\"Poisson Log-Likelihood vs Lambda\")\nplt.grid(True)\nplt.show()\n\ntodo: If you’re feeling mathematical… show lambda_mle = Ȳ\nTo find the MLE, we take the derivative of the log-likelihood:\n[ () = ( -+ Y_i () - (Y_i!) ) ]\nTaking the derivative with respect to λ and setting it to zero:\n[ = -n + Y_i = 0 _{} = Y_i = {Y} ]\nSo, the MLE of λ is the sample mean.\ntodo: Find the MLE by optimizing your likelihood function with sp.optimize\n\nfrom scipy.optimize import minimize_scalar\nresult = minimize_scalar(\n    lambda l: -poisson_loglikelihood(l, Y),\n    bounds=(0.001, 10),\n    method='bounded'\n)\n\nprint(\"MLE for lambda:\", result.x)\n\n\n\nnext section"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file.\nAbout this site"
  },
  {
    "objectID": "projects/project1/HW2/hw2_questions.html",
    "href": "projects/project1/HW2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_regression_loglik(beta, X, Y):\n    eta = X @ beta  # linear predictor\n    lambda_ = np.exp(eta)  # inverse link function\n    if np.any(lambda_ &lt;= 0):\n        return -np.inf\n    return np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/project1/HW2/hw2_questions.html#blueprinty-case-study",
    "href": "projects/project1/HW2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef poisson_regression_loglik(beta, X, Y):\n    eta = X @ beta  # linear predictor\n    lambda_ = np.exp(eta)  # inverse link function\n    if np.any(lambda_ &lt;= 0):\n        return -np.inf\n    return np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/project1/HW2/hw2_questions.html#airbnb-case-study",
    "href": "projects/project1/HW2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "My Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "projects/project1/HW1/HW.html",
    "href": "projects/project1/HW1/HW.html",
    "title": "Scotland's Website",
    "section": "",
    "text": "import pandas as pd\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n\ndf = pd.read_stata(\"/home/jovyan/Desktop/quarto_website1/HW1/karlan_list_2007.dta\")\ndf['ratio1'] = (df['ratio'] == 1).astype(int)\n\n\nlist(df.columns)\n\n['treatment',\n 'control',\n 'ratio',\n 'ratio2',\n 'ratio3',\n 'size',\n 'size25',\n 'size50',\n 'size100',\n 'sizeno',\n 'ask',\n 'askd1',\n 'askd2',\n 'askd3',\n 'ask1',\n 'ask2',\n 'ask3',\n 'amount',\n 'gave',\n 'amountchange',\n 'hpa',\n 'ltmedmra',\n 'freq',\n 'years',\n 'year5',\n 'mrm2',\n 'dormant',\n 'female',\n 'couple',\n 'state50one',\n 'nonlit',\n 'cases',\n 'statecnt',\n 'stateresponse',\n 'stateresponset',\n 'stateresponsec',\n 'stateresponsetminc',\n 'perbush',\n 'close25',\n 'red0',\n 'blue0',\n 'redcty',\n 'bluecty',\n 'pwhite',\n 'pblack',\n 'page18_39',\n 'ave_hh_sz',\n 'median_hhincome',\n 'powner',\n 'psch_atlstba',\n 'pop_propurban',\n 'ratio1']\n\n\n\ndf\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\nratio1\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n1\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n1\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n1\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n0\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n0\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n0\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n0\n\n\n\n\n50083 rows × 52 columns\n\n\n\n\nimport numpy as np\n\ndef welch_t_test(x, y):\n    # Drop missing values\n    x = x.dropna()\n    y = y.dropna()\n\n    # Sample sizes\n    n_x = len(x)\n    n_y = len(y)\n\n    # Sample means\n    mean_x = np.mean(x)\n    mean_y = np.mean(y)\n\n    # Sample variances\n    var_x = np.var(x, ddof=1)\n    var_y = np.var(y, ddof=1)\n\n    # Welch's t-statistic\n    numerator = mean_x - mean_y\n    denominator = np.sqrt((var_x / n_x) + (var_y / n_y))\n\n    if denominator == 0:\n        return np.nan\n\n    t_stat = numerator / denominator\n    return t_stat\n\n\n\ncovariates = [\n    'mrm2', 'hpa', 'years', 'female', 'couple',\n    'pwhite', 'pblack', 'ave_hh_sz', 'median_hhincome'\n]\n\nfor var in covariates:\n    print(f\"\\n--- Manual Welch t-test for {var} ---\")\n    x = df[df['treatment'] == 1][var]\n    y = df[df['treatment'] == 0][var]\n    t_stat = welch_t_test(x, y)\n    print(f\"t = {t_stat:.4f}\")\n    # Linear regression\n    model = smf.ols(f\"{var} ~ treatment\", data=df).fit()\n    coef = model.params['treatment']\n    p = model.pvalues['treatment']\n    print(f\"Regression: coef = {coef:.3f}, p = {p:.4f}\")\n\n\n--- Manual Welch t-test for mrm2 ---\nt = 0.1195\nRegression: coef = 0.014, p = 0.9049\n\n--- Manual Welch t-test for hpa ---\nt = 0.9704\nRegression: coef = 0.637, p = 0.3451\n\n--- Manual Welch t-test for years ---\nt = -1.0909\nRegression: coef = -0.058, p = 0.2700\n\n--- Manual Welch t-test for female ---\nt = -1.7535\nRegression: coef = -0.008, p = 0.0787\n\n--- Manual Welch t-test for couple ---\nt = -0.5823\nRegression: coef = -0.002, p = 0.5594\n\n--- Manual Welch t-test for pwhite ---\nt = -0.5590\nRegression: coef = -0.001, p = 0.5753\n\n--- Manual Welch t-test for pblack ---\nt = 0.0975\nRegression: coef = 0.000, p = 0.9219\n\n--- Manual Welch t-test for ave_hh_sz ---\nt = 0.8234\nRegression: coef = 0.003, p = 0.4098\n\n--- Manual Welch t-test for median_hhincome ---\nt = -0.7433\nRegression: coef = -157.925, p = 0.4583\n\n\n\nimport matplotlib.pyplot as plt\n\n\n\ngroup_totals = df.groupby('treatment')['amount'].sum()\n\ngroup_totals.index = ['Control', 'Treatment']\n\nplt.figure(figsize=(6, 5))\ngroup_totals.plot(kind='bar', color=['skyblue', 'salmon'])\n\nplt.title('Total Donations Raised by Group')\nplt.ylabel('Total Dollars Raised')\nplt.xlabel('Group')\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\n\n\ncontrol_gave = df[df['treatment'] == 0]['gave'].dropna()\ntreatment_gave = df[df['treatment'] == 1]['gave'].dropna()\n\nt_stat, p_val = ttest_ind(treatment_gave, control_gave, equal_var=False)\nprint(f\"T-test: t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nT-test: t = 3.209, p = 0.0013\n\n\n\nimport statsmodels.formula.api as smf\n\nmodel = smf.ols('gave ~ treatment', data=df).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        17:04:45   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nimport statsmodels.api as sm\n\ndf['intercept'] = 1  # probit model requires intercept manually\nprobit_model = sm.Probit(df['gave'], df[['intercept', 'treatment']]).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        17:04:45   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Filter groups\nr1 = df[df['ratio'] == 1]['gave']\nr2 = df[df['ratio2'] == 1]['gave']\nr3 = df[df['ratio3'] == 1]['gave']\n\n# T-tests\nprint(\"T-test: 2:1 vs 1:1\")\nprint(ttest_ind(r2, r1, equal_var=False))\n\nprint(\"\\nT-test: 3:1 vs 1:1\")\nprint(ttest_ind(r3, r1, equal_var=False))\n\nprint(\"\\nT-test: 3:1 vs 2:1\")\nprint(ttest_ind(r3, r2, equal_var=False))\n\nT-test: 2:1 vs 1:1\nTtestResult(statistic=0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836)\n\nT-test: 3:1 vs 1:1\nTtestResult(statistic=1.0150174470156275, pvalue=0.31010856527625774, df=22215.0529778684)\n\nT-test: 3:1 vs 2:1\nTtestResult(statistic=0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778)\n\n\n\nimport statsmodels.formula.api as smf\n\nmodel = smf.ols('gave ~ ratio1 + ratio2 + ratio3', data=df).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        17:04:45   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\ncoef_r2 = model.params.get('ratio2', 0)\ncoef_r3 = model.params.get('ratio3', 0)\nprint(f\"\\nDifference 2:1 vs 1:1: {coef_r2:.4f}\")\nprint(f\"Difference 3:1 vs 1:1: {coef_r3:.4f}\")\nprint(f\"Difference 3:1 vs 2:1: {coef_r3 - coef_r2:.4f}\")\n\n\nDifference 2:1 vs 1:1: 0.0048\nDifference 3:1 vs 1:1: 0.0049\nDifference 3:1 vs 2:1: 0.0001\n\n\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n\n\ncontrol_amt = df[df['treatment'] == 0]['amount']\ntreatment_amt = df[df['treatment'] == 1]['amount']\nt_stat, p_val = ttest_ind(treatment_amt, control_amt, equal_var=False)\nprint(f\"T-test (all data): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\n# Bivariate regression\nmodel = smf.ols('amount ~ treatment', data=df).fit()\nprint(model.summary())\n\nT-test (all data): t = 1.918, p = 0.0551\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        17:04:45   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\ndf_donors = df[df['amount'] &gt; 0]\n\nc_amt = df_donors[df_donors['treatment'] == 0]['amount']\nt_amt = df_donors[df_donors['treatment'] == 1]['amount']\nt_stat, p_val = ttest_ind(t_amt, c_amt, equal_var=False)\nprint(f\"T-test (donors only): t = {t_stat:.3f}, p = {p_val:.4f}\")\n\nmodel_donors = smf.ols('amount ~ treatment', data=df_donors).fit()\nprint(model_donors.summary())\n\nT-test (donors only): t = -0.585, p = 0.5590\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        17:04:45   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nimport matplotlib.pyplot as plt\n\n\ncontrol = df_donors[df_donors['treatment'] == 0]['amount']\ntreatment = df_donors[df_donors['treatment'] == 1]['amount']\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\naxes[0].hist(control, bins=30, color='skyblue', edgecolor='black')\naxes[0].axvline(control.mean(), color='red', linestyle='dashed', label=f'Mean: ${control.mean():.2f}')\naxes[0].set_title('Control Group - Donation Amounts')\naxes[0].set_xlabel('Donation Amount ($)')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\naxes[1].hist(treatment, bins=30, color='salmon', edgecolor='black')\naxes[1].axvline(treatment.mean(), color='red', linestyle='dashed', label=f'Mean: ${treatment.mean():.2f}')\naxes[1].set_title('Treatment Group - Donation Amounts')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nn = 10000\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\n\ncontrol_draws = np.random.binomial(n=1, p=p_control, size=n)\ntreatment_draws = np.random.binomial(n=1, p=p_treatment, size=n)\n\ndifferences = treatment_draws - control_draws\n\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n + 1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff, label='Cumulative Avg. Difference')\nplt.axhline(true_diff, color='red', linestyle='dashed', label='True Difference = 0.004')\nplt.title(\"Law of Large Numbers: Cumulative Avg. Difference in Donation Rates\")\nplt.xlabel(\"Number of Simulated Pairs\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis simulation shows how the average difference in donation rates between treatment and control groups stabilizes as the sample size increases. Although early values fluctuate due to randomness, the cumulative average converges to the true difference (0.004) as more data is added. This demonstrates the Law of Large Numbers: with enough observations, sample averages reliably approach their expected values.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\ncontrol_p = 0.018\ntreat_p = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Set up plots\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        control = np.random.binomial(1, control_p, n)\n        treat = np.random.binomial(1, treat_p, n)\n        diffs.append(np.mean(treat) - np.mean(control))\n    \n    # Plot histogram\n    axes[i].hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='dashed', label='Zero')\n    axes[i].set_title(f'Sample Size = {n}')\n    axes[i].set_xlabel('Avg. Difference in Means')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAs sample size increases, the distribution of average differences becomes more concentrated and symmetric, illustrating the Central Limit Theorem. With small samples (e.g., 50), the spread is wide and variable. But by n = 1000, the distribution is nearly normal and centered around the true mean difference. Importantly, zero is in the tail, not the center, suggesting that the effect of the treatment is consistently positive across simulations."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Estimation of Simple Poisson Model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\nYour Name\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\nScotland Muir\nMay 7, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  }
]