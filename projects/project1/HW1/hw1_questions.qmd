---
title: "A Replication of Karlan and List (2007)"
author: "Scotland Muir"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
execute:
  echo: true       # Show code
  output: true     # Show output
  warning: false
  message: false
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2). In a large-scale natural field experiment, Dean Karlan and John List partnered with a liberal nonprofit organization (that focuses on Civil Rights) in the United States to investigate how matching gift offers affect charitable giving. The donations will be tax-deuctible for federal income taxes. The study involved 50,083 individuals who had donated to the organization at least once since 1991. These prior donors were randomly divided into a control group and a treatment group. The control group received a standard direct mail fundraising letter, while the treatment group received an otherwise identical letter that included a matching grant offer from a “concerned fellow member.” Within the treatment group, participants were further randomly assigned to different variations across three key dimensions: (1) the match ratio—$1:$1, $2:$1, or $3:$1; (2) the maximum amount available from the matching donor—$25,000, $50,000, $100,000, or unspecified; and (3) the suggested donation amount, which was either equal to, 1.25 times, or 1.5 times the recipient’s previous highest contribution. These design elements allowed the researchers to isolate and test the effects of both the presence and structure of matching incentives on giving behavior. All letters were mailed in August 2005, and the fundraising appeal was tied to a current political issue at the time—Supreme Court nominations—to enhance relevance and urgency.


This project seeks to replicate their results.


## Data

### Description

The dataset includes donation outcomes (whether and how much was donated), treatment assignments (match ratio, maximum match amount, suggested donation), and individual donor history (e.g., prior donation amount and frequency). It also incorporates ZIP code-level demographics (income, education, race, household size), political context (red/blue state, voted for bush, and county), and nonprofit activity levels by state. This structure enables analysis of treatment effects and heterogeneity across political and demographic groups.

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::
```python
df = pd.read_stata("/home/jovyan/Desktop/quarto_website1/HW1/karlan_list_2007.dta")
df['ratio1'] = (df['ratio'] == 1).astype(int)
```


### Balance Test

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

```python
import numpy as np
import statsmodels.formula.api as smf

def welch_t_test(x, y):
    x = x.dropna()
    y = y.dropna()
    n_x, n_y = len(x), len(y)
    mean_x, mean_y = np.mean(x), np.mean(y)
    var_x, var_y = np.var(x, ddof=1), np.var(y, ddof=1)
    denominator = np.sqrt((var_x / n_x) + (var_y / n_y))
    if denominator == 0:
        return np.nan
    return (mean_x - mean_y) / denominator

covariates = [
    'mrm2', 'hpa', 'years', 'female', 'couple',
    'pwhite', 'pblack', 'ave_hh_sz', 'median_hhincome'
]

for var in covariates:
    print(f"\n--- Manual Welch t-test for {var} ---")
    x = df[df['treatment'] == 1][var]
    y = df[df['treatment'] == 0][var]
    t_stat = welch_t_test(x, y)
    print(f"t = {t_stat:.4f}")

    # Linear regression comparison
    model = smf.ols(f"{var} ~ treatment", data=df).fit()
    coef = model.params['treatment']
    p = model.pvalues['treatment']
    print(f"Regression: coef = {coef:.3f}, p = {p:.4f}")
```

### Balance Test Results Summary

The Welch t-tests and linear regressions across the selected covariates indicate that there are no statistically significant differences between the treatment and control groups. This suggests that the randomization process successfully created. These balance test results support the internal validity of the experimental design by confirming that any observed differences in outcomes can likely be attributed to the treatment rather than to pre-existing group differences.



## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

_todo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control._
```python
import matplotlib.pyplot as plt

group_totals = df.groupby('treatment')['amount'].sum()
group_totals.index = ['Control', 'Treatment']
plt.figure(figsize=(6, 5))
group_totals.plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('Total Donations Raised by Group')
plt.ylabel('Total Dollars Raised')
plt.xlabel('Group')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()
```

_todo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)_

```python
from scipy.stats import ttest_ind

control_gave = df[df['treatment'] == 0]['gave'].dropna()
treatment_gave = df[df['treatment'] == 1]['gave'].dropna()

t_stat, p_val = ttest_ind(treatment_gave, control_gave, equal_var=False)
print(f"T-test: t = {t_stat:.3f}, p = {p_val:.4f}")
```

The t-test shows a statistically significant difference in donation rates between the treatment and control groups (t = 3.209, p = 0.0013), supporting the hypothesis that offering a matching donation increases the likelihood of giving. This suggests that people are more inclined to donate when they perceive their contribution to have greater impact, highlighting how behavioral cues like matching grants can effectively nudge charitable behavior.

_todo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper._
```python
import statsmodels.formula.api as smf

model = smf.ols('gave ~ treatment', data=df).fit()
print(model.summary())
```


my results do compare to table 3

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

_todo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the "figures suggest" comment the authors make on page 8?_
```python
from scipy.stats import ttest_ind

r1 = df[df['ratio'] == 1]['gave']
r2 = df[df['ratio2'] == 1]['gave']
r3 = df[df['ratio3'] == 1]['gave']

print("T-test: 2:1 vs 1:1")
print(ttest_ind(r2, r1, equal_var=False))

print("\nT-test: 3:1 vs 1:1")
print(ttest_ind(r3, r1, equal_var=False))

print("\nT-test: 3:1 vs 2:1")
print(ttest_ind(r3, r2, equal_var=False))
```

Yes these results support what the authors said on page 8

#### Interpretation
my results show no statistically significant difference in donation rates between any of the match ratios tested. In other words, increasing the match ratio from 1:1 to 2:1 or 3:1 did not make people more likely to donate.

_todo: Assess the same issue using a regression. Specifically, create the variable `ratio1` then regress `gave` on `ratio1`, `ratio2`, and `ratio3` (or alternatively, regress `gave` on the categorical variable `ratio`). Interpret the coefficients and their statistical precision._

```python
import statsmodels.formula.api as smf
model = smf.ols('gave ~ ratio1 + ratio2 + ratio3', data=df).fit()
print(model.summary())
```


The regression shows that 2:1 and 3:1 match ratios significantly increase donation rates compared to the base group. However, their effects are nearly identical, suggesting no added benefit from raising the match beyond 2:1. This supports the paper’s conclusion that while matching boosts giving, higher ratios don’t lead to more donations.


_todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.  Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?_
```python
coef_r2 = model.params.get('ratio2', 0)
coef_r3 = model.params.get('ratio3', 0)
print(f"\nDifference 2:1 vs 1:1: {coef_r2:.4f}")
print(f"Difference 3:1 vs 1:1: {coef_r3:.4f}")
print(f"Difference 3:1 vs 2:1: {coef_r3 - coef_r2:.4f}")
```

The regression shows that both 2:1 and 3:1 match ratios increase donation rates by about 0.5 percentage points compared to 1:1. But there’s almost no difference between 2:1 and 3:1, so bigger match ratios don’t seem to help more. It looks like just having a match matters more than how big it is.

### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

_todo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?_
```python
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

control_amt = df[df['treatment'] == 0]['amount']
treatment_amt = df[df['treatment'] == 1]['amount']
t_stat, p_val = ttest_ind(treatment_amt, control_amt, equal_var=False)
print(f"T-test (all data): t = {t_stat:.3f}, p = {p_val:.4f}")
```

The t-test shows a small difference in donation amounts between the treatment and control groups, with the treatment group giving slightly more on average. However, the result is not statistically significant (p = 0.0551), meaning we cannot confidently conclude that the treatment had an effect on how much people donated.

_todo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients -- what did we learn? Does the treatment coefficient have a causal interpretation?_ 
```python
df_donors = df[df['amount'] > 0]

c_amt = df_donors[df_donors['treatment'] == 0]['amount']
t_amt = df_donors[df_donors['treatment'] == 1]['amount']
t_stat, p_val = ttest_ind(t_amt, c_amt, equal_var=False)
print(f"T-test (donors only): t = {t_stat:.3f}, p = {p_val:.4f}")

model_donors = smf.ols('amount ~ treatment', data=df_donors).fit()
print(model_donors.summary())
```

The regression shows that among those who donated, individuals in the treatment group gave about $1.67 less than those in the control group, but this difference is not statistically significant (p = 0.561). This suggests that while matching offers increase the likelihood of donating, they do not affect the donation amount once a person chooses to give. Therefore, we cannot draw a causal conclusion about the treatment’s impact on contribution size.


_todo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot._
```python
import matplotlib.pyplot as plt


control = df_donors[df_donors['treatment'] == 0]['amount']
treatment = df_donors[df_donors['treatment'] == 1]['amount']

fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)

axes[0].hist(control, bins=30, color='skyblue', edgecolor='black')
axes[0].axvline(control.mean(), color='red', linestyle='dashed', label=f'Mean: ${control.mean():.2f}')
axes[0].set_title('Control Group - Donation Amounts')
axes[0].set_xlabel('Donation Amount ($)')
axes[0].set_ylabel('Frequency')
axes[0].legend()

axes[1].hist(treatment, bins=30, color='salmon', edgecolor='black')
axes[1].axvline(treatment.mean(), color='red', linestyle='dashed', label=f'Mean: ${treatment.mean():.2f}')
axes[1].set_title('Treatment Group - Donation Amounts')
axes[1].set_xlabel('Donation Amount ($)')
axes[1].legend()

plt.tight_layout()
plt.show()
```

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

_to do:  Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means._
```python
import numpy as np
import matplotlib.pyplot as plt


n = 10000
p_control = 0.018
p_treatment = 0.022
true_diff = p_treatment - p_control

control_draws = np.random.binomial(n=1, p=p_control, size=n)
treatment_draws = np.random.binomial(n=1, p=p_treatment, size=n)

differences = treatment_draws - control_draws

cumulative_avg_diff = np.cumsum(differences) / np.arange(1, n + 1)

plt.figure(figsize=(10, 6))
plt.plot(cumulative_avg_diff, label='Cumulative Avg. Difference')
plt.axhline(true_diff, color='red', linestyle='dashed', label='True Difference = 0.004')
plt.title("Law of Large Numbers: Cumulative Avg. Difference in Donation Rates")
plt.xlabel("Number of Simulated Pairs")
plt.ylabel("Cumulative Average Difference")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
```


This simulation shows how the average difference in donation rates between treatment and control groups stabilizes as the sample size increases. Although early values fluctuate due to randomness, the cumulative average converges to the true difference (0.004) as more data is added. This demonstrates the Law of Large Numbers: with enough observations, sample averages reliably approach their expected values.

### Central Limit Theorem

_to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the "middle" of the distribution or whether it's in the "tail."_
```python
import numpy as np
import matplotlib.pyplot as plt


control_p = 0.018
treat_p = 0.022
sample_sizes = [50, 200, 500, 1000]
n_simulations = 1000


fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.flatten()

for i, n in enumerate(sample_sizes):
    diffs = []
    for _ in range(n_simulations):
        control = np.random.binomial(1, control_p, n)
        treat = np.random.binomial(1, treat_p, n)
        diffs.append(np.mean(treat) - np.mean(control))
    
 
    axes[i].hist(diffs, bins=30, color='skyblue', edgecolor='black')
    axes[i].axvline(0, color='red', linestyle='dashed', label='Zero')
    axes[i].set_title(f'Sample Size = {n}')
    axes[i].set_xlabel('Avg. Difference in Means')
    axes[i].set_ylabel('Frequency')
    axes[i].legend()

plt.tight_layout()
plt.show()

```

As sample size increases, the distribution of average differences becomes more concentrated and symmetric, illustrating the Central Limit Theorem. With small samples (e.g., 50), the spread is wide and variable. But by n = 1000, the distribution is nearly normal and centered around the true mean difference. Importantly, zero is in the tail, not the center, suggesting that the effect of the treatment is consistently positive across simulations.



